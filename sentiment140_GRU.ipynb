{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sentiment140_GRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherkhalil/COVID19/blob/master/sentiment140_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q4pskaVy2L62",
        "colab": {}
      },
      "source": [
        "#path = '/content/drive/'\n",
        "#p = path + 'My Drive/Thesis New Data/Data from Dr. Anwar Ali Yahya'\n",
        "dataset = '/content/drive/My Drive/NLP/twitter_sentiments.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj7u74JNpD0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "b58dd699-dd9d-4253-a93f-3bee9245f2a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6kw-IcMg4Ps_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "3efe7ecf-9cae-4c31-b065-f5a5d1cd7b0f"
      },
      "source": [
        "import pandas as pd \n",
        "data = pd.read_csv(dataset,encoding='ISO-8859-1',names=[\"Label\", \"COL2\", \"COL3\", \"COL4\",\"COL5\",\"Tweet\"]) \n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>COL2</th>\n",
              "      <th>COL3</th>\n",
              "      <th>COL4</th>\n",
              "      <th>COL5</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label  ...                                              Tweet\n",
              "0      0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1      0  ...  is upset that he can't update his Facebook by ...\n",
              "2      0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3      0  ...    my whole body feels itchy and like its on fire \n",
              "4      0  ...  @nationwideclass no, it's not behaving at all....\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40DAVJh5wTGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d09b98bd-b227-4a8e-e1e8-8ded2b230147"
      },
      "source": [
        "data.Label.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    800000\n",
              "0    800000\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D-h7fP6o44Xf",
        "colab": {}
      },
      "source": [
        "data['Label_Numeric'] = data['Label'].map({0:0, 4:1})"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG9xuPo1ilII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "668fa753-dc81-4917-93dc-d12518f6b28d"
      },
      "source": [
        "data['Label_Numeric'].head()\n",
        "data.Label_Numeric.value_counts()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    800000\n",
              "0    800000\n",
              "Name: Label_Numeric, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ECfRi-DD5Ha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "38b59045-9c9d-4812-fedc-05ed31cc5be2"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "\n",
        "\n",
        "from keras import backend as K\n",
        "#K.tensorflow_backend._get_available_gpus()\n",
        "\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "maxlen = 280\n",
        "max_words = 40000\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "#tokenizer.fit_on_texts(data['Tweet'])\n",
        "#sequences = tokenizer.texts_to_sequences(data['Tweet'])\n",
        "\n",
        "tokenizer.fit_on_texts(data['Tweet'])\n",
        "sequences = tokenizer.texts_to_sequences(data['Tweet'])\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "data1 = pad_sequences(sequences, maxlen=maxlen)\n",
        "print(data1)\n",
        "def to_one_hot(labels, dimension=2):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results\n",
        "one_hot_labels = to_one_hot(data['Label_Numeric'])\n",
        "labels = np.asarray(one_hot_labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "indices = np.arange(data1.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data1 = data1[indices]\n",
        "labels = labels[indices]\n",
        "\"\"\"x_train = data1[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data1[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]\n",
        "x_test = data1[validation_samples: validation_samples + test_samples]\n",
        "y_test = labels[validation_samples: validation_samples + test_samples]\"\"\"\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data1, labels, test_size=0.1, random_state=0)\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.03, random_state=0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 690960 unique tokens.\n",
            "[[    0     0     0 ...    41     9   385]\n",
            " [    0     0     0 ...    40   273  1170]\n",
            " [    0     0     0 ...    31    12 27341]\n",
            " ...\n",
            " [    0     0     0 ...    14    11  2107]\n",
            " [    0     0     0 ...  5325    50 13870]\n",
            " [    0     0     0 ...     0   119 20040]]\n",
            "Shape of data tensor: (1600000, 7)\n",
            "Shape of label tensor: (1600000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZFH_G83H7wvb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "73f5b90f-36ae-4cb0-8181-be2ef5eb641a"
      },
      "source": [
        "print(labels.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1600000, 2)\n",
            "(160000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4u-l1FRLFLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1b7fd750-e8cc-4ee2-a232-68f739e1e584"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1440000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8uMuCIRtIYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "37cb9b76-4136-4b0d-b5c7-3ac669174bfe"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense, Dropout\n",
        "from keras.layers import Embedding, LSTM\n",
        "from keras import regularizers\n",
        "from keras import layers\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import TimeDistributed\n",
        "embedding_dim = 300\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model3.add(layers.GRU(32,return_sequences = True, dropout=0.2,recurrent_dropout=0.2))\n",
        "model3.add(layers.GRU(32, return_sequences= True))\n",
        "model3.add(layers.GlobalMaxPooling1D())\n",
        "model3.add(layers.Dense(10, activation='relu'))\n",
        "model3.add(layers.Dense(2, activation='sigmoid'))\n",
        "model3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model3.summary()\n",
        "\n",
        "\n",
        "\n",
        "history = model3.fit(X_train, y_train, epochs=10, batch_size=2048, validation_split = 0.1, shuffle=True)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 280, 300)          12000000  \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 280, 32)           31968     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 280, 32)           6240      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 12,038,560\n",
            "Trainable params: 12,038,560\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 1296000 samples, validate on 144000 samples\n",
            "Epoch 1/10\n",
            "1296000/1296000 [==============================] - 390s 301us/step - loss: 0.4462 - accuracy: 0.7902 - val_loss: 0.4010 - val_accuracy: 0.8179\n",
            "Epoch 2/10\n",
            "1296000/1296000 [==============================] - 387s 298us/step - loss: 0.3825 - accuracy: 0.8279 - val_loss: 0.3881 - val_accuracy: 0.8245\n",
            "Epoch 3/10\n",
            "1296000/1296000 [==============================] - 385s 297us/step - loss: 0.3595 - accuracy: 0.8406 - val_loss: 0.3863 - val_accuracy: 0.8252\n",
            "Epoch 4/10\n",
            "1296000/1296000 [==============================] - 385s 297us/step - loss: 0.3419 - accuracy: 0.8497 - val_loss: 0.3875 - val_accuracy: 0.8254\n",
            "Epoch 5/10\n",
            "1296000/1296000 [==============================] - 385s 297us/step - loss: 0.3261 - accuracy: 0.8581 - val_loss: 0.3928 - val_accuracy: 0.8259\n",
            "Epoch 6/10\n",
            "1296000/1296000 [==============================] - 385s 297us/step - loss: 0.3109 - accuracy: 0.8658 - val_loss: 0.3986 - val_accuracy: 0.8241\n",
            "Epoch 7/10\n",
            "1296000/1296000 [==============================] - 384s 296us/step - loss: 0.2961 - accuracy: 0.8731 - val_loss: 0.4079 - val_accuracy: 0.8228\n",
            "Epoch 8/10\n",
            "1296000/1296000 [==============================] - 384s 296us/step - loss: 0.2820 - accuracy: 0.8801 - val_loss: 0.4204 - val_accuracy: 0.8210\n",
            "Epoch 9/10\n",
            "1296000/1296000 [==============================] - 386s 298us/step - loss: 0.2689 - accuracy: 0.8861 - val_loss: 0.4353 - val_accuracy: 0.8217\n",
            "Epoch 10/10\n",
            "1296000/1296000 [==============================] - 384s 296us/step - loss: 0.2576 - accuracy: 0.8912 - val_loss: 0.4460 - val_accuracy: 0.8190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_xzMIGbLCzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score , recall_score\n",
        "y_val_pred=model3.predict_classes(X_test)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBiZVD2Lrv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "8e11951d-f721-49e1-bf74-085ac4690855"
      },
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "rounded_labels=np.argmax(y_test, axis=1)\n",
        "\n",
        "\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(rounded_labels, y_val_pred)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(rounded_labels, y_val_pred)\n",
        "print('Precision: %f' %precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(rounded_labels, y_val_pred, average = 'weighted')\n",
        "print('Recall: %f' %recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(rounded_labels, y_val_pred)\n",
        "print('F1: %f' %f1)\n",
        "# accuracy: (tp + tn) / (p + n)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.818319\n",
            "Precision: 0.820122\n",
            "Recall: 0.818319\n",
            "F1: 0.817480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re7FEDjrLt-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}